\documentclass{article}
\usepackage{amsmath}
\begin{document}
What we want to calculate in using QMC
\begin{equation}
\frac{dE}{dp} = \int dR \Psi^2 \frac{H\Psi}{\Psi} \frac{\partial_p \Psi}{\Psi}  - \int dR \Psi^2 \frac{H\Psi}{\Psi} \int dR \Psi^2 \frac{\partial_p \Psi}{\Psi}.
\end{equation}
A naive estimator of this quantity using QMC would be 
\begin{equation}
\frac{1}{M-1}\sum_{i=1}^{M-1} \Bigg(\frac{H\Psi(R_i)}{\Psi} - \frac{1}{M} \sum_{j=1}^{M} \frac{H\Psi(R_j)}{\Psi}\Bigg)\frac{\partial_p \Psi(R_i)}{\Psi}
\end{equation}
This estimator is unbiased but has an infinite variance. The infinity arises in the following term in the expression for the variance, which diverges near the nodes
$$ 
\int dR \Psi^2 (\frac{H\Psi}{\Psi} \frac{\partial_p \Psi}{\Psi})^2.
$$
This is most clearly seen by decomposing the dR near the nodes into a surface element dN along the nodal surface and a line element normal to the nodal surface dl: $dR = dN dl$.

\begin{equation}
\int dR \Psi^2 (\frac{H\Psi}{\Psi}\frac{\partial_p \Psi}{\Psi})^2 \rightarrow \int dN \frac{(H(N) \partial_p \Psi(N))^2}{|\nabla\Psi(N)|^2} \int dl \frac{1}{l^2} 
\end{equation}
which clearly diverges.

\section{A regularized estimator} 
We can deal with this divergence by considering an estimator of the following form for the divergent term:
\begin{equation}
  \theta(x) = \left.
  \begin{cases}
    \frac{H\Psi}{\Psi} \frac{\partial_p \Psi}{\Psi}, & l \geq \epsilon \\
    \frac{H\Psi}{\Psi} \frac{\partial_p \Psi}{\Psi} f(l), & l < \epsilon \\
  \end{cases}
  \right\}
\end{equation}
where $\epsilon$ is a cutoff constant which is to be chosen. If $f(l)$ behaves with the condition 

\begin{equation}
\lim_{l\rightarrow 0} f(l) = l^n, \ n \geq 1 
\end{equation}
then the variance term will be convergent. 

\subsection{Bias}
While any function $f(l)$ can be chosen with condition (5), an arbitrary function will introduce a bias which is non-vanishing for \textit{any} $\epsilon  > 0$ into the quantity we want to evaluate, i.e. the first term in equation (1). 
We would like to avoid this systematic bias as the variance will increasing unboundedly as $\epsilon \rightarrow 0$, leaving the extrapolation practically impossible as $\epsilon \rightarrow 0$.

In order to ensure that the bias is zero to lowest order, we demand an additional constraint for $f(l)$. 
Let's expand the term we want to calculate about the node again:

$$\int dN \int_{-\epsilon}^{\epsilon}dl \ (H(N) + O(l) + O(l^2)) (\partial_p\Psi(N) + O(l) + O(l^2)) $$
The bias under this Taylor expansion takes the form 
\begin{equation}
\text{Bias } = \int dN \int_{-\epsilon}^{\epsilon}dl \ (H(N) + O(l) + O(l^2)) (\partial_p\Psi(N) + O(l) + O(l^2))( f(l) - 1 ) = 
\end{equation}
$$
\int_{-\epsilon}^{\epsilon} dl H(N)\partial_p\Psi(N)(f(l) - 1) + O(\epsilon^3)
$$
assuming that $f(l)$ is even across the node (which we'd definitely like).
Therefore, if we can satisfy the following condition, we get a well behaved bias.
\begin{equation}
\int_{-\epsilon}^{\epsilon} f(l) - 1 = 0 \rightarrow \text{Bias} = O(\epsilon^3)
\end{equation}

\subsection{Smoothness} 
Now we would also prefer to have this estimator be smooth as smooth stochastic estimators tend to have a smaller bias. The smoothness conditions are then 

\begin{equation}
f(\epsilon) = f(-\epsilon) = 1, f^\prime(\epsilon) = f^\prime(-\epsilon) =0
\end{equation}

\subsection{The final estimator} 
We therefore need to satisfy (6), (7) and (8) for a good estimator. This will have finite variance, bias $O(\epsilon^3)$ and be smooth.

Since the function needs to be even for all values of $\epsilon$, f(l) can be expanded in even polynomials. Condition (6) ensures that no constant can exist, and the three additional constraints of (7) and (8) means that we can exactly satisfy all the constraints with the following form

\begin{equation}
f(l) = al^2 + bl^4 + cl^6 
\end{equation}
Doing a big of algebra, we can find the following quantities for the variables a, b, c:
\begin{equation}
c = \frac{7}{\epsilon^6}, 
b = \frac{-1 - 2c\epsilon^6}{\epsilon^4}, 
a = -2b\epsilon^2 -3c\epsilon^4
\end{equation}

\end{document}